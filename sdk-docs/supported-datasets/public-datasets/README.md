# Public Datasets

Codeset provides access to a variety of public datasets for training and evaluating agentic code models.

## Training

Training datasets are used to train agentic code models, providing them with a large corpus of environments each containing a problem statement, a repo state, and a verifier.

| Name | Type of Tasks | # Samples | # Repos | Language(s) | Availability |
| --- | --- | --- | --- | --- | --- |
| [SWE-Gym](https://github.com/SWE-Gym/SWE-Gym) | Bug-fixing, feature addition | 2,400 | 11 | Python | <span style="color:grey;">Planned</span> |
| [R2E-Gym](https://github.com/R2E-Gym/R2E-Gym) | Bug-fixing, feature addition | 8,135 | 13 | Python | <span style="color:grey;">Planned</span> |
| [SWE-Smith](https://github.com/SWE-bench/SWE-smith) | Synthetic bug-fixing, feature addition, etc. | 50,000 | 128 | Python | <span style="color:grey;">Planned</span> |

## Evaluation

Evaluation datasets are used to benchmark and assess the performance of models on specific coding tasks. They provide a standardized set of problems to measure an agent's ability to solve bugs, implement features, or perform other software engineering tasks.

| Name | Type of Tasks | # Samples | # Repos | Language(s) | Availability |
| --- | --- | --- | --- | --- | --- |
| [GitBug-Java](https://github.com/gitbugactions/gitbug-java) | Bug-fixing | 199 | 55 | Java | <span style="color:grey;">Planned</span> |
| [SWE-bench](https://github.com/SWE-bench/SWE-bench) | Bug-fixing, feature addition | 2,294 | 12 | Python | <span style="color:grey;">Planned</span> |
| [Multi-SWE-bench](https://multi-swe-bench.github.io/) | Bug-fixing | 1,632 | 33 | Java, TypeScript, JavaScript, Go, Rust, C, and C++ | <span style="color:grey;">Planned</span> |
